{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875b60b-7d4c-4e3a-9751-c9432c395590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at EleutherAI/gpt-j-6B were not used when initializing GPTJForCausalLM: ['transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.10.attn.bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.12.attn.bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.13.attn.bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.14.attn.bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.15.attn.bias', 'transformer.h.15.attn.masked_bias', 'transformer.h.16.attn.bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.17.attn.bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.18.attn.bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.19.attn.bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.20.attn.bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.21.attn.bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.22.attn.bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.23.attn.bias', 'transformer.h.23.attn.masked_bias', 'transformer.h.24.attn.bias', 'transformer.h.24.attn.masked_bias', 'transformer.h.25.attn.bias', 'transformer.h.25.attn.masked_bias', 'transformer.h.26.attn.bias', 'transformer.h.26.attn.masked_bias', 'transformer.h.27.attn.bias', 'transformer.h.27.attn.masked_bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.bias', 'transformer.h.9.attn.masked_bias']\n",
      "- This IS expected if you are initializing GPTJForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTJForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the professor's name:  Asadpour\n",
      "Enter your research topic:  AI\n",
      "Enter your name:  Masih\n"
     ]
     
 ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import os\n",
    "\n",
    "# Load the tokenizer and model for GPT-J\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "\n",
    "# Set the padding token to the EOS token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_email(professor_name, research_topic, user_name):\n",
    "    # Email template\n",
    "    prompt = f\"\"\"\n",
    "    Dear Professor {professor_name},\n",
    "\n",
    "    I am writing to express my interest in pursuing research under your guidance. My research topic revolves around {research_topic}.\n",
    "\n",
    "    I believe that your work in this area is groundbreaking, and I am eager to contribute to your ongoing projects.\n",
    "\n",
    "    Best regards,\n",
    "    {user_name}\n",
    "    \"\"\"\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    # Generate email with controlled randomness\n",
    "    output = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=len(inputs[\"input_ids\"][0]) + 100,\n",
    "        do_sample=True,  # Set to True to use temperature and top_p\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    # Decode and return the text\n",
    "    generated_email = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_email.strip()\n",
    "\n",
    "def text_to_speech(text, output_file=\"email.mp3\", lang='en'):\n",
    "    try:\n",
    "        if os.path.exists(output_file):\n",
    "            os.remove(output_file)\n",
    "        tts = gTTS(text, lang=lang)\n",
    "        tts.save(output_file)\n",
    "        print(f\"Speech saved to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating speech: {e}\")\n",
    "\n",
    "def play_sound(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"File not found.\")\n",
    "        return\n",
    "    try:\n",
    "        # Using playsound\n",
    "        playsound(file_path)\n",
    "        print(\"\\nEmail is being read aloud.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing sound with playsound: {e}\")\n",
    "\n",
    "# Input data\n",
    "professor_name = input(\"Enter the professor's name: \")\n",
    "research_topic = input(\"Enter your research topic: \")\n",
    "user_name = input(\"Enter your name: \")\n",
    "\n",
    "# Generate and print the email\n",
    "email = generate_email(professor_name, research_topic, user_name)\n",
    "print(\"\\nGenerated Email:\\n\")\n",
    "print(email)\n",
    "\n",
    "# Convert the email to speech\n",
    "text_to_speech(email)\n",
    "\n",
    "# Play the generated speech\n",
    "play_sound(\"email.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc527f-4f37-44d3-8454-52a980cf6038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
